{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matiasmolinolo/anaconda3/envs/iag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NADE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size):\n",
    "        super(NADE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.W_in = nn.Parameter(torch.randn(input_dim, hidden_size))\n",
    "        self.b_in = nn.Parameter(torch.randn(input_dim))\n",
    "\n",
    "        self.W_hidden = nn.Parameter(torch.randn(hidden_size, input_dim))\n",
    "        self.b_hidden = nn.Parameter(torch.randn(hidden_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        num_features = x.shape[1]\n",
    "\n",
    "        a = self.b_hidden\n",
    "        \n",
    "        probs = torch.zeros(batch_size, num_features)\n",
    "\n",
    "        for i in range(num_features):\n",
    "            h = torch.sigmoid(a).reshape(-1, self.hidden_size)\n",
    "            probs[:, i] = torch.sigmoid(self.W_in[i, :] @ h.T + self.b_in[i])\n",
    "            a = torch.matmul(self.W_hidden[:, i].reshape(-1, 1), x[:, i].reshape(1, -1)).reshape(-1, self.hidden_size) + a\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def sample(self, device):\n",
    "        with torch.no_grad():\n",
    "            preds = torch.zeros(1, self.input_dim).to(device)\n",
    "            for i in tqdm(range(self.input_dim)):\n",
    "                p = self.forward(preds)\n",
    "                preds[:, i] = torch.bernoulli(p[:, i])\n",
    "            \n",
    "            return torch.reshape(preds, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 784\n",
    "hidden_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    lambda x: (x >= 0.5).float(),\n",
    "])\n",
    "\n",
    "original_train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "original_test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "filter_digit = 3\n",
    "\n",
    "filtered_train_dataset = [item for item in original_train_dataset if item[1] == filter_digit]\n",
    "filtered_test_dataset = [item for item in original_test_dataset if item[1] == filter_digit]\n",
    "\n",
    "filtered_dataset = filtered_train_dataset + filtered_test_dataset\n",
    "\n",
    "data_loader = DataLoader(filtered_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nade = NADE(in_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss().to(device)\n",
    "optim = optim.Adam(nade.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 0, Loss: 10.172370910644531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:14,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.2683634757995605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [00:16,  6.99it/s]\n",
      "2it [00:00,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 0, Loss: 1.250388741493225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 100, Loss: 1.134709358215332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [00:14,  7.99it/s]\n",
      "2it [00:00,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 0, Loss: 1.1261060237884521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:13,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 100, Loss: 1.0388706922531128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [00:14,  7.60it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch, (data, _) in tqdm(enumerate(data_loader)):\n",
    "        data = data.view(in_size, -1)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        output = nade(data.to(device))\n",
    "        loss = criterion(output.to(device), data.to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Batch: {batch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nade, 'nade.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 784/784 [00:40<00:00, 19.38it/s]\n"
     ]
    }
   ],
   "source": [
    "img = nade.sample(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(img):\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_sample(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
